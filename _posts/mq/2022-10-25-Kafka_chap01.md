---
layout: post
title: Kafka Cluster, Producer, Consumer
summary: Kafka
author: devhtak
date: '2022-10-25 14:41:00 +0900'
category: mq
---

#### 카프카 브로커와 클러스터

- 브로커는 카프카 클라이언트와 데이터를 주고받기 위해 사용하는 주체
- 브로커 1대로도 기본 기능이 실행되지만, 데이터를 안전하게 보관하고 처리하기 위해 3대 이상의 브로커 서버를 1개의 클러스터로 묶어서 운영
- 데이터 저장, 전송
  - 프로듀서로부터 전달된 데이터는 파일 시스템에 저장된다
    - 카프카는 메모리나 데이터베이스에 저장하지 않으며 따로 캐시메모리를 구현하여 사용하지 않는다
  - 파일입출력에 대한 이슈에 대한 고민
    - 페이지 캐시를 사용하여 디스크 입출력 속도를 높여서 해결

- 데이터 복제, 싱크
  - 데이터 복제(replication)의 이유는 클러스터로 묶인 브로커 중 일부가 장애가 발생하더라도 데이터를 유실하지 않고 안전하게 사용하기 위함이다
  - 카프카의 데이터 복제는 파티션 단위로 이뤄진다
    - 복제된 파티션은 리더와 팔로워로 구성
    - 팔로워는 리더 파티션의 오프셋을 확인하여 현재 자신이 가지고 있는 오프셋과 차이나는 경우 리더로부터 데이터를 가져와 자신의 파티션에 저장
    - 브로커 장애로 리더 파티션을 사용할 수 없게 되면 팔로워 중 리더를 선출한다.
  - 운영에서는 데이터 종류마다 복제 개수를 설정하고, 상황에 따라 토픽마다 복제 개수를 다르게 운영한다
    - 데이터 속도가 중요하다면 1 또는 2 설정, 데이터 유실이 고민인 경우 복제 개수를 3으로 설정하여 2개의 브로커에 장애가 발생해도 데이터를 안정적으로 처리할 수 있도록 유지한다

- 컨트롤러
  - 클러스터 내의 다수 브로커 중 한대가 컨트롤러 역할을 한다
  - 다른 브로커들의 상태를 체크하고 브로커가 클러스터에서 빠지는 경우 해당 브로커에 존재하는 리더 파티션을 재분배한다

- 데이터 삭제
  - 컨슈머가 데이터를 가져가더라도 토픽의 데이터는 삭제되지 않는다
  - 브로커만이 삭제할 수 있으며, 삭제는 파일 단위로 이루어지고, 이를 로그 세그먼트라 한다
  - log.segment.bytes, log.segment.ms 옵션 값으로 용량을 설정할 수 있다

- 컨슈머 오프셋 저장
  - 컨슈머는 특정 파티션으로부터 데이터를 가져가서 처리하고, 레코드를 가져간 값을 확인하기 위해 오프셋을 커밋한다
  - 커밋한 오프셋은 \_consumer_offsets 토픽에 저장
  
- 코디네이터
  - 클러스터 내의 다수 브로커 중 한대는 코디네이터 역할 수행
  - 코디네이터는 컨슈머 그룹의 상태를 체크하고 파티션을 컨슈머와 매칭되도록 분배하는 역할을 한다
  - 리밸런스
    - 파티션을 컨슈머로 재할당하는 과정

- 주키퍼
  - 주키퍼는 카프카의 메타데이터를 관리하는 데 사용
  - 카프카 클러스터로 묶인 브로커들은 동일한 경로의 주키퍼 경로로 선언해야 같은 카프카 브로커 묶음이 된다

#### 토픽과 파티션

- 토픽은 카프카에서 데이터를 구분하기 위해 사용하는 단위이며, 저장되는 데이터를 레코드라고 한다
- 파티션은 카프카의 병렬처리의 핵심으로 그룹으로 묶인 컨슈머들이 레코드를 병렬로 처리할 수 있도록 매칭
- 파티션은 큐와 비슷한 구조지만, pop으로 레코드를 삭제하지 않고 파일시스템에 저장된다

#### 레코드

- 레코드는 타임스탬프, 메시지 키, 메시지 값, 오프셋, 헤더로 구성되어 있다
- 타임스탬프는 프로듀서에서 해당 레코드가 생성된 시점으로 토픽 설정에 따라 브로커에 적재된 시간으로 설정될수도 있다
- 메시지 키는 메시지 값을 순서대로 처리하거나 메시지 값의 종류를 나타내기 위해 사용
- 메시지값은 실질적으로 처리할 데이터가 들어 있다
- 헤더는 레코드의 추가적인 정보를 담는 메타데이터 저장소로 사용

#### 프로듀서

- 프로듀서는 카프카에 필요한 데이터를 선언하고 브로커의 특정 토픽의 파티션에 전송
- 중요 개념
  
  <img width="714" alt="image" src="https://user-images.githubusercontent.com/42403023/197794762-d6ced810-f161-4507-b80e-a1f4cc601ff0.png">
  
  - 프로듀서는 카프카 브로커로 데이터를 전송할 때 내부적으로 파티셔너, 배치 생성 단계를 거친다
  - 전송하고자 하는 데이터는 ProducerRecord 클래스를 통해 인스턴스를 생성
    - 파티션 번호를 직접 지정하거나 타임스탬프를 설정, 메시지 키를 설정할 수 있다
  - KafkaProducer 인스턴스가 send() 호출 -> ProducerRecord는 파티셔너에서 토픽의 어느 파티션으로 전송될 것인지 정해진다
    - 기본값인 DefaultPartitioner로 설정되어 파티션이 저장
    - 파티셔너에 의해 구분된 레코드는 데이터를 전송하기 전에 어큐뮬레이터(accumulator)에 데이터를 버퍼로 쌓아놓고 발송
    - 버퍼로 쌓인 데이터는 배치로 묶어 전송함으로써 처치량 향상
    - 프로듀서 API를 사용하면 UniformStickyPartioner, RoundRobinPartitioner를 제공
    - UniformStickyPartioner는 RoundRobinPartitioner 에 단점 개선
    - UniformStickyPartioner 는 프로듀서 동작에 특화되어 높은 처리량과 낮은 리소스 사용률을 가지는 특성이 있다
  - Partitioner 인터페이스
    - 인터페이스를 상속받아 메시지 키, 값에 따라 파티션을 지정할 수 있도록 적용할 수 있다.
    - 파티셔너를 통해 파티션이 지정된 데이터는 어큐뮬레이터에 버퍼로 쌓인다
  - 압축 옵션을 통해 브로커로 데이터를 전송할 수 있다
  
- 기본 옵션
  - bootstrap.servers
    - 카프카 클러스터에 속한 브로커의 호스트이름:포트 를 1개 이상 작성
  - key.serializer
    - 레코드의 메시지 키를 직렬화하는 클래스 지정
  - value.serializer
    - 레코드의 메시지 값을 직렬화하는 클래스 지정
  - acks
    - 브로커에 레코드를 정상 저장되었는지 전송 성공 여부 확인
    - 0: 프로듀서가 전송한 즉시 브로커에 데이터 저장 여부와 상관없이 성공으로 판단
    - -1(all): 토픽의 miin.insync.replicas 개수에 해당하는 리더 파티션과 팔로워 파티션에 데이터가 저장되면 성공한 것으로 판단
    - 1(default): 리더 파티션에 데이터가 저장되면 성공 판단
  - buffer.memory
    - 브로커로 전송할 데이터를 배치로 모으기 위해 설정할 버퍼 메모리 양
  - retries
    - 브로커로부터 에러를 받고 난 뒤 재전송을 시도하는 횟수
  - batch.size
    - 배치로 전송할 레코드 최대 용량 지정
  - linger.ms
    - 배치를 전송하기 전까지 기다리는 최소 시간, 기본은 0
  - partitioner.class
    - 레코드를 파티션에 전송할 때 적용하는 파티셔너 클래스 지정
  - enable.idempotence
    - 멱등성 프로듀서 동작 여부 설정
  - transation.id
    - 레코드를 전송할 때 트랜잭션 단위로 묶을 지 여부 설정
    - 이 값을 설정하면 트랜잭션 프로듀서로 동작

- 메시지 키를 가진 데이터
  - ProducerRecord를 생성할 때, 토픽 이름, 메시지 키, 값 을 넣고 생성
  ```java
  ProducerRecord<String, String> record = new ProducerRecord<>("test", "Pangyo", "23");
  // TOMIC_NAME, messageKey, messageValue
  ```
- 파티션 번호를 가진 데이터
  - ProducerRecord를 생성할 때, 토픽 이름, 파티션 번호, 메시지 키, 값을 넣고 생성
  ```java
  ProducerRecord<String, String> record = new ProducerRecord<>("test", 0, "Pangyo", "23");
  // TOMIC_NAME, partitionNo, messageKey, messageValue
  ```
- 커스텀 파티셔너를 갖는 프로듀서
  - 프로듀서 사용환경에 따라 특정 데이터를 가지는 레코드를 특정 파티션으로 보내야 하는 경우
  - Partitoner 인터페이스를 사용하여 사용자 정의 파티셔너를 생성하여 지정할 수 있다
  ```java
  // Pangyo 라는 키가 들어오면 무조건 0번 파티션으로 보내도록 설정
  public class CustomPartitioner implements Partitioner {
      @Override
      public int partition(String topic, Object key, byte[] keyBytes, Object value, byte[] valueBytes, Cluster cluster) {
          if(keyBytes == null {
              throw new InvalidRecordException("Need message key");
          }
          if((String)key.equals("Pangyo")) {
              return 0;
          }
          
          List<PartitionInfo> partitions = cluster.partitionsForTopic(topic);
          int numPartitions = partitions.size();
          return Utils.toPosivice(Utils.murmur2(keyBytes)) % numberPartitions;
      }
      
      @Override
      public void configure(Map<String, ?> configs) {}
      
      @Override
      public void close() {}
  }
  ```
  - partitioner.class 설정해 주어야 한다

- 브로커 정상 전송 여부 확인
  - Callback을 생성하여, producer.send(data, callback) 형식으로 전송한다.
  ```java
  @Slf4j
  public class ProducerCallback implemments Callback {
      @Override
      public void onComplete(RecordMetadata recordMetadata, Exception e) {
          if(e != null) {
              logger.error(e.getMessage(), e);
          }else {
              logger.info(recordMetadata.toString());
          }
      }
  }
  ```
  ```java
  KafkaProducer<String, String> producer = new KafkaProducer(configs);
  ProducerRecord<String, String> record = new ProducerRecord<>(TOPIC_NAME, messageValue);
  producer.send(record, new ProducerCallback());
  ```

#### 컨슈머

- 중요 개념
  - 컨슈머 운영 방법
    - 한개 이상의 컨슈머로 컨슈머 그룹을 운영
    - 특정 파티션만 구독하는 컨슈머 운영
  - 컨슈머 그룹을 운영할 때에는 파티션에 개수와 같거나 작아야 한다
  - 컨슈머 그룹은 다른 컨슈머 그룹과 격리되는 특징을 갖고 있다
    - 다양한 저장소에 저장하는 파이프라인을 구축할 때 각기 다른 저장소에 저장하는 컨슈머 그룹을 구성하면 격리되어 운영할 수 있다
  - 리밸런싱
    - 컨슈머 그룹으로 이루어진 컨슈머 중 일부 장애가 발생하면, 장애가 발생한 컨슈머에 할당된 파티션은 다른 컨슈머에 소유권을 넘긴다.
    - 컨슈머가 추가되거나 제외될 때 사용
  - 오프셋 커밋
    - 컨슈머는 카프카 브로커로부터 데이터를 어디까지 가져갔는지 커밋을 통해 기록(토픽: _consumer_topic)
    - 데이터 중복이 발생하지 않게 하기 위해 오프셋 커밋을 정상 처리했는 지 검증해야 한다
    - poll() 메서드가 수행될 때 일정 간격마다 오프셋을 커밋하도록 enable.auto.commit=true 로 설정
    - auto.commit.interval.ms 에 설정된 값을 통해 간격을 지정
    - poll() 메서드 호출 이후에 리밸런싱 또는 컨슈머 종료 발생시 데이터 중복, 유실 가능성이 있다
    - 데이터 중복이나 유실을 허용하지 않는 서비스라면 자동 커밋을 사용히먄 인되고 동기 커밋(commitSync())를 호출해야 한다
  - 컨슈머 내부 구조
  
    <img width="495" alt="image" src="https://user-images.githubusercontent.com/42403023/198304998-660b0275-f0af-4c3e-9bc9-ec40283fe054.png">
    - 컨슈머는 poll 메서드를 통해 레코드를 반환받지만, Fetcher 인스턴스가 생성되어 poll() 메서드를 호출하기 전에 미리 레코드들을 내부 큐로 가져온다
    - 이후에 poll() 메서드를 호출하면 컨슈머는 내부 큐에 있는 레코드를 반환받아 처리

- 컨슈머 주요 옵션
  - boostrap.servers
    - 카프카 클러스터에 속한 브로커의 호스트 이름:포트를 1개 이상 작성
  - key.deserializer
    - 레코드의 메시지 키를 역직렬화하는 클래스 지정
  - value.deserializer
    - 레코드의 메시지 값을 역직렬화하는 클래스 지정
  - group.id
    - 컨슈머 그룹 아이디 지정
    - subscribe() 메서드로 토픽을 구독하여 사용할 때 해당 옵션을 필수로 넣어야 한다
  - auto.offset.reset
    - 컨슈머 그룹이 특정 파티션을 읽을 때 지정된 컨슈머 오프셋이 없는 경우 어느 오프셋부터 읽을 지 선택하는 옵션
    - latest: 가장 높은 오프셋부터 읽기 시작
    - earilest: 가장 낮은 오프셋부터 읽기 시작
    - none: 컨슈머 그룹이 커밋한 기록이 있는지 찾아본다. 없으면 오류, 있으면 기록 이후 오프셋부터 읽기 시작
  - enable.auto.commit
    - 자동, 수동 커밋 여부 선택
  - auto.commit.interval.ms
    - 자동 커밋 간격 지정
  - max.poll.records
    - poll() 메서드를 통해 반환되는 레코드 개수 지정
  - session.timeout.ms
    - 컨슈머가 브로커와 연결이 끊기는 최대 시간
    - 이 시간내에 heartbeat를 전송하지 않으면 브로커는 컨슈머에 이슈가 발생했다고 가정하고 리밸런싱 진행
  - heartbeat.interval.ms
    - 하트비트 전송 시간 간격
  - max.poll.interval.ms
    - poll() 메서드를 호출하는 간격의 최대 시간 지정
  - isolation.level
    - 트랜잭션 프로듀서가 레코드를 트랜잭션 단위로 보낼 경우 사용
    - read_commited: 커밋이 완료된 레코드만 읽는다
    - read_uncommited: 커밋 여부와 관계없이 파티션에 있는 모든 레코드를 읽는다(default)

#### 출처

- 책: 아파치 카프카 애플리케이션 프로그래밍 with 자바
