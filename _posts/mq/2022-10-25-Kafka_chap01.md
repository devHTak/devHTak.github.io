---
layout: post
title: Kafka Cluster, Producer, Consumer
summary: Kafka
author: devhtak
date: '2022-10-25 14:41:00 +0900'
category: mq
---

#### 카프카 브로커와 클러스터

- 브로커는 카프카 클라이언트와 데이터를 주고받기 위해 사용하는 주체
- 브로커 1대로도 기본 기능이 실행되지만, 데이터를 안전하게 보관하고 처리하기 위해 3대 이상의 브로커 서버를 1개의 클러스터로 묶어서 운영
- 데이터 저장, 전송
  - 프로듀서로부터 전달된 데이터는 파일 시스템에 저장된다
    - 카프카는 메모리나 데이터베이스에 저장하지 않으며 따로 캐시메모리를 구현하여 사용하지 않는다
  - 파일입출력에 대한 이슈에 대한 고민
    - 페이지 캐시를 사용하여 디스크 입출력 속도를 높여서 해결

- 데이터 복제, 싱크
  - 데이터 복제(replication)의 이유는 클러스터로 묶인 브로커 중 일부가 장애가 발생하더라도 데이터를 유실하지 않고 안전하게 사용하기 위함이다
  - 카프카의 데이터 복제는 파티션 단위로 이뤄진다
    - 복제된 파티션은 리더와 팔로워로 구성
    - 팔로워는 리더 파티션의 오프셋을 확인하여 현재 자신이 가지고 있는 오프셋과 차이나는 경우 리더로부터 데이터를 가져와 자신의 파티션에 저장
    - 브로커 장애로 리더 파티션을 사용할 수 없게 되면 팔로워 중 리더를 선출한다.
  - 운영에서는 데이터 종류마다 복제 개수를 설정하고, 상황에 따라 토픽마다 복제 개수를 다르게 운영한다
    - 데이터 속도가 중요하다면 1 또는 2 설정, 데이터 유실이 고민인 경우 복제 개수를 3으로 설정하여 2개의 브로커에 장애가 발생해도 데이터를 안정적으로 처리할 수 있도록 유지한다

- 컨트롤러
  - 클러스터 내의 다수 브로커 중 한대가 컨트롤러 역할을 한다
  - 다른 브로커들의 상태를 체크하고 브로커가 클러스터에서 빠지는 경우 해당 브로커에 존재하는 리더 파티션을 재분배한다

- 데이터 삭제
  - 컨슈머가 데이터를 가져가더라도 토픽의 데이터는 삭제되지 않는다
  - 브로커만이 삭제할 수 있으며, 삭제는 파일 단위로 이루어지고, 이를 로그 세그먼트라 한다
  - log.segment.bytes, log.segment.ms 옵션 값으로 용량을 설정할 수 있다

- 컨슈머 오프셋 저장
  - 컨슈머는 특정 파티션으로부터 데이터를 가져가서 처리하고, 레코드를 가져간 값을 확인하기 위해 오프셋을 커밋한다
  - 커밋한 오프셋은 \_consumer_offsets 토픽에 저장
  
- 코디네이터
  - 클러스터 내의 다수 브로커 중 한대는 코디네이터 역할 수행
  - 코디네이터는 컨슈머 그룹의 상태를 체크하고 파티션을 컨슈머와 매칭되도록 분배하는 역할을 한다
  - 리밸런스
    - 파티션을 컨슈머로 재할당하는 과정

- 주키퍼
  - 주키퍼는 카프카의 메타데이터를 관리하는 데 사용
  - 카프카 클러스터로 묶인 브로커들은 동일한 경로의 주키퍼 경로로 선언해야 같은 카프카 브로커 묶음이 된다

#### 토픽과 파티션

- 토픽은 카프카에서 데이터를 구분하기 위해 사용하는 단위이며, 저장되는 데이터를 레코드라고 한다
- 파티션은 카프카의 병렬처리의 핵심으로 그룹으로 묶인 컨슈머들이 레코드를 병렬로 처리할 수 있도록 매칭
- 파티션은 큐와 비슷한 구조지만, pop으로 레코드를 삭제하지 않고 파일시스템에 저장된다

#### 레코드

- 레코드는 타임스탬프, 메시지 키, 메시지 값, 오프셋, 헤더로 구성되어 있다
- 타임스탬프는 프로듀서에서 해당 레코드가 생성된 시점으로 토픽 설정에 따라 브로커에 적재된 시간으로 설정될수도 있다
- 메시지 키는 메시지 값을 순서대로 처리하거나 메시지 값의 종류를 나타내기 위해 사용
- 메시지값은 실질적으로 처리할 데이터가 들어 있다
- 헤더는 레코드의 추가적인 정보를 담는 메타데이터 저장소로 사용

#### 프로듀서

- 프로듀서는 카프카에 필요한 데이터를 선언하고 브로커의 특정 토픽의 파티션에 전송
- 중요 개념
  
  <img width="714" alt="image" src="https://user-images.githubusercontent.com/42403023/197794762-d6ced810-f161-4507-b80e-a1f4cc601ff0.png">
  
  - 프로듀서는 카프카 브로커로 데이터를 전송할 때 내부적으로 파티셔너, 배치 생성 단계를 거친다
  - 전송하고자 하는 데이터는 ProducerRecord 클래스를 통해 인스턴스를 생성
    - 파티션 번호를 직접 지정하거나 타임스탬프를 설정, 메시지 키를 설정할 수 있다
  - KafkaProducer 인스턴스가 send() 호출 -> ProducerRecord는 파티셔너에서 토픽의 어느 파티션으로 전송될 것인지 정해진다
    - 기본값인 DefaultPartitioner로 설정되어 파티션이 저장
    - 파티셔너에 의해 구분된 레코드는 데이터를 전송하기 전에 어큐뮬레이터(accumulator)에 데이터를 버퍼로 쌓아놓고 발송
    - 버퍼로 쌓인 데이터는 배치로 묶어 전송함으로써 처치량 향상
    - 프로듀서 API를 사용하면 UniformStickyPartioner, RoundRobinPartitioner를 제공
    - UniformStickyPartioner는 RoundRobinPartitioner 에 단점 개선
    - UniformStickyPartioner 는 프로듀서 동작에 특화되어 높은 처리량과 낮은 리소스 사용률을 가지는 특성이 있다
  - Partitioner 인터페이스
    - 인터페이스를 상속받아 메시지 키, 값에 따라 파티션을 지정할 수 있도록 적용할 수 있다.
    - 파티셔너를 통해 파티션이 지정된 데이터는 어큐뮬레이터에 버퍼로 쌓인다
  - 압축 옵션을 통해 브로커로 데이터를 전송할 수 있다
  
- 기본 옵션
  - bootstrap.servers
  - key.serializer
  - value.serializer
  - acks
  - buffer.memory
  - retries
  - batch.size
  - linger.ms
  - partitioner.class
  - enable.idempotence
  - transation.id

- 메시지 키를 가진 데이터
  - ProducerRecord를 생성할 때, 토픽 이름, 메시지 키, 값 을 넣고 생성
- 파티션 번호를 가진 데이터
  - ProducerRecord를 생성할 때, 토픽 이름, 파티션 번호, 메시지 키, 값을 넣고 생성
- 커스텀 파티셔너를 갖는 프로듀서
  - 

#### 출처

- 책: 아파치 카프카 애플리케이션 프로그래밍 with 자바
#### 토픽과 파티션
